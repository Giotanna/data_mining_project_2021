{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Random Forest').getOrCreate()\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from ipynb.fs.full.Knn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0    Male  67.0             0              1          Yes        Private   \n",
       "1  Female  61.0             0              0          Yes  Self-employed   \n",
       "2    Male  80.0             0              1          Yes        Private   \n",
       "3  Female  49.0             0              0          Yes        Private   \n",
       "4  Female  79.0             1              0          Yes  Self-employed   \n",
       "\n",
       "  Residence_type  avg_glucose_level   smoking_status   bmi  stroke  \n",
       "0          Urban             228.69  formerly smoked  30.8       1  \n",
       "1          Rural             202.21     never smoked  28.3       1  \n",
       "2          Rural             105.92     never smoked  30.9       1  \n",
       "3          Urban             171.23           smokes  28.5       1  \n",
       "4          Rural             174.12     never smoked  30.2       1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>ever_married</th>\n      <th>work_type</th>\n      <th>Residence_type</th>\n      <th>avg_glucose_level</th>\n      <th>smoking_status</th>\n      <th>bmi</th>\n      <th>stroke</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Male</td>\n      <td>67.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>228.69</td>\n      <td>formerly smoked</td>\n      <td>30.8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Female</td>\n      <td>61.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Self-employed</td>\n      <td>Rural</td>\n      <td>202.21</td>\n      <td>never smoked</td>\n      <td>28.3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Male</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>105.92</td>\n      <td>never smoked</td>\n      <td>30.9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Female</td>\n      <td>49.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>171.23</td>\n      <td>smokes</td>\n      <td>28.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Female</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Self-employed</td>\n      <td>Rural</td>\n      <td>174.12</td>\n      <td>never smoked</td>\n      <td>30.2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Replace 'other' with most frequent gender\n",
    "df = df4.copy()\n",
    "df['gender'].replace('Other', df4['gender'].value_counts().idxmax(), inplace=True)\n",
    "df['gender'].unique()\n",
    "\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange the columns so that we can easily track the index of columns for ColumnTransformer\n",
    "X = df.drop(['stroke'],axis=1)\n",
    "Y = df['stroke']\n",
    "\n",
    "X_category = X.select_dtypes(include='object')\n",
    "X_numeric = X.select_dtypes(exclude='object')\n",
    "\n",
    "X = pd.concat([X_category, X_numeric], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the preprocessing pipeline\n",
    "#transform the numerical columns by imputting followed by scaling\n",
    "imp_std = Pipeline(\n",
    "    steps=[\n",
    "        ('impute', SimpleImputer(strategy='median')),\n",
    "        ('scale', StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#pass this pipeline along with OneHotEncoder to ColumnsTransformer to do the Preprocessing stuff\n",
    "ct = ColumnTransformer(\n",
    "    remainder='passthrough',\n",
    "    transformers = [\n",
    "        (\"Encoding\",OneHotEncoder(),[0,1,2,3,4]),\n",
    "        (\"Scaler\", imp_std,[5,6,7,8,9])\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train_idle, X_test_idle, y_train, y_test = train_test_split(X, Y, test_size=0.25, stratify=Y)\n",
    "\n",
    "# Fit our transformers to train set\n",
    "ct.fit(X_train_idle)\n",
    "\n",
    "# Transform both train and test set\n",
    "X_train = ct.transform(X_train_idle)\n",
    "X_test = ct.transform(X_test_idle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying SMOTE to oversample the dataset in hope that the models can learn more efficiently\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "#X_train_resampled, y_train_resampled = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "models['Random Forest'] = RandomForestClassifier(class_weight={0:1,1:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Forest : fit\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    models[model].fit(X_train_resampled, y_train_resampled)\n",
    "    print(model + ' : fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train set prediction\n",
      "------------------------Random Forest------------------------\n",
      "[[3645    0]\n",
      " [   0 3645]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3645\n",
      "           1       1.00      1.00      1.00      3645\n",
      "\n",
      "    accuracy                           1.00      7290\n",
      "   macro avg       1.00      1.00      1.00      7290\n",
      "weighted avg       1.00      1.00      1.00      7290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The performance on train set is (too) good. That's because we use SMOTE. It makes model learn very well because of having a perfect balance dataset\n",
    "print(\"Train set prediction\")\n",
    "for x in models:\n",
    "        \n",
    "    print('------------------------'+x+'------------------------')\n",
    "    model = models[x]\n",
    "    y_train_pred = model.predict(X_train_resampled)\n",
    "    arg_train = {'y_true':y_train_resampled, 'y_pred':y_train_pred}\n",
    "    print(confusion_matrix(**arg_train))\n",
    "    print(classification_report(**arg_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test set prediction\n------------------------Random Forest------------------------\n[[1162   54]\n [  49   13]]\n              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96      1216\n           1       0.19      0.21      0.20        62\n\n    accuracy                           0.92      1278\n   macro avg       0.58      0.58      0.58      1278\nweighted avg       0.92      0.92      0.92      1278\n\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set prediction\")\n",
    "for x in models:\n",
    "        \n",
    "    print('------------------------'+x+'------------------------')\n",
    "    model = models[x]\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    arg_test = {'y_true':y_test, 'y_pred':y_test_pred}\n",
    "    print(confusion_matrix(**arg_test))\n",
    "    print(classification_report(**arg_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}